# ðŸ¤– SQL ECOMMERCE Agent

A web-based application built with Streamlit that allows users to query their product data using natural language. Powered by a Large Language Model (LLM), this agent converts English questions into SQL queries, fetches results from a local SQLite database, and presents them in a human-readable format.


# âœ¨ Features

1.Natural Language to SQL: Converts user questions (e.g., "Show me total sales for item_id 25") into executable SQLite queries.

2.Local Data Integration: Connects to a local SQLite database (product_data.db) populated from your CSV datasets (Product-Level Eligibility, Total Sales, Ad Sales).

3.Flexible LLM Backend: Supports both local LLMs , cloud-based LLM APIs like Google Gemini.

4.Interactive Web UI: A simple and intuitive Streamlit interface for asking questions and viewing results.

5.Modular Design: Structured into separate Python modules (llm.py, sql.py, agent.py, app.py) for maintainability and scalability.


# ðŸš€ Getting Started
Follow these steps to set up and run the AI SQL Agent on your local machine.

âœ… Prerequisites

* Python 3.8+

* Git


* For Google Gemini API: A Google AI Studio API Key.

# ðŸ“¦ Installation


1. Install Python dependencies:

    CODE: pip install -r requirements.txt


2. Set up your LLM API Key (if using Google Gemini):
Create a file named .env in the root of your project directory and add your Google API key:

3.  .env
GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY_HERE"

4. âš™ Setup & Run
Prepare your Database:
Run the sql.py script once to download your CSV data from Google Sheets and populate the product_data.db SQLite database.

CODE: python sql.py

You should see messages about successful downloads and data imports.

Start your LLM Service:

If using Google Gemini API: No separate server is needed, but ensure you have an active internet connection and your GOOGLE_API_KEY is correctly set in .env.

Run the Streamlit Application:

Open a terminal, navigate to your project's root directory, and run the Streamlit app:

CODE: streamlit run app.py

This will open the application in your web browser, usually at http://localhost:8501/.

ðŸ“‚ Project Structure
E-commerce-agent/

â”œâ”€â”€ app.py       
        # Streamlit web interface
â”œâ”€â”€ agent.py  
          # Core AI agent logic (orchestrates LLM and DB)
â”œâ”€â”€ llm.py   
           # LLM service (handles communication with Ollama/Gemini API)
â”œâ”€â”€ sql.py   
        # Database service (handles SQLite connection, table creation, CSV import)
â”œâ”€â”€ .env   
        # Environment variables (e.g., GOOGLE_API_KEY)
â”œâ”€â”€ product_data.db 
        # SQLite database file (generated by sql.py)
â”œâ”€â”€ requirements.txt 
        # Python dependencies


# ðŸ“š Dependencies
The main dependencies are listed in requirements.txt:

streamlit

python-dotenv

requests

ollama

openai

google-generativeai # Only if using Google Gemini API

#sqlite3 is built-in with Python
